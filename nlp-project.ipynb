{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hey README, tell me your secrets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Scrape READMEs in github to determine their respective programing language\n",
    "\n",
    "To Do: \n",
    "- Find readmes to scrape, at least 100 \n",
    "- Pull content\n",
    "\n",
    "Findings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# modules\n",
    "import acquire\n",
    "import prepare\n",
    "#import explore\n",
    "import model\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of 100 pages to scrape are generated using the `acquire.loop_through_urls` function. They are saved to a csv and that csv file is being read for further manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_scrape = acquire.loop_through_urls()\n",
    "# to_scrape = pd.DataFrame(to_scrape)\n",
    "# to_scrape.to_csv(\"URL_list_100_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of pages generated from function \n",
    "pd.read_csv(\"URL_list_100.csv\", header=0, names=[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe of 100 pages that was just created is looped through, and on each page, it's respective repository, language, and readme is extracted as a dictionary, using the `acquire.make_corpus` function. \n",
    "\n",
    "The `acquire.get_corpus` fuction checks to see if the data file is in the cache. If it is, it reads it in as a dataframe, if file is not in cache, the above mentioned function is run to generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = acquire.get_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy for prepping and exploring\n",
    "df = df_init.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `prepare.cut_singles` function, remove the languages that only have a single readme represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.cut_singles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare.prep_readme(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"readme\"] = df.readme.apply(prepare.better_clean).apply(prepare.remove_stopwords).apply(prepare.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the breakdown of programming languages \n",
    "explore.count_percent(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.readme_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.readme_length(df).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Model will use the entire 100 rows of corpus. It is then stripped of unnecssary characters and brokend down into \n",
    "\n",
    "components with lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = acquire.get_corpus('data_final.json')\n",
    "# df['prepared'] = df.readme.apply(prepare.basic_clean).apply(prepare.remove_stopwords).apply(prepare.lemmatize)\n",
    "# df = prepare.cut_singles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = acquire.get_corpus('data_final.json')\n",
    "df2 = pd.read_json('data_second.json')\n",
    "frames = [df1,df2]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prepared'] = df.readme.apply(prepare.basic_clean).apply(prepare.remove_numbers).apply(prepare.remove_stopwords).apply(prepare.lemmatize)\n",
    "df = prepare.cut_singles(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is broken into training and testing sets. In this instance it will be a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, train, test = model.make_model_components(df.prepared, df.language, .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model.make_tree_model(X_train, train.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = classifier.predict(X_train)\n",
    "train['predictions'] = training_predictions\n",
    "test_predictions = classifier.predict(X_test)\n",
    "test['predictions'] = test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy scores for the model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.61%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual       C  C++  CSS  Go  Java  JavaScript  None  Python  TypeScript  Vue\n",
      "predictions                                                                  \n",
      "C++          0    2    0   0     0           0     0       1           0    0\n",
      "CSS          0    0    2   0     0           0     0       0           0    0\n",
      "Go           3    4    1   7     1           2     4       3           3    0\n",
      "Java         0    0    0   0    10           0     0       0           0    0\n",
      "JavaScript   0    0    1   0     0          41     0       0           0    0\n",
      "None         0    0    0   0     0           0    17       0           0    0\n",
      "Python       0    3    0   0     0           1     0      12           0    0\n",
      "TypeScript   0    0    0   0     0           0     0       0           4    2\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.00      0.00      0.00         3\n",
      "         C++       0.67      0.22      0.33         9\n",
      "         CSS       1.00      0.50      0.67         4\n",
      "          Go       0.25      1.00      0.40         7\n",
      "        Java       1.00      0.91      0.95        11\n",
      "  JavaScript       0.98      0.93      0.95        44\n",
      "        None       1.00      0.81      0.89        21\n",
      "      Python       0.75      0.75      0.75        16\n",
      "  TypeScript       0.67      0.57      0.62         7\n",
      "         Vue       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.77       124\n",
      "   macro avg       0.63      0.57      0.56       124\n",
      "weighted avg       0.83      0.77      0.77       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.score_your_model(train.actual, train.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy scores for the model on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.24%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual       C  C++  CSS  Go  Java  JavaScript  None  Python  TypeScript  Vue\n",
      "predictions                                                                  \n",
      "C++          0    0    0   1     0           0     0       0           0    0\n",
      "Go           1    1    0   1     1           1     3       1           1    0\n",
      "Java         0    0    0   0     3           0     0       0           0    0\n",
      "JavaScript   0    1    1   0     0          10     2       0           1    0\n",
      "None         0    0    0   0     0           3     3       2           0    0\n",
      "Python       0    1    0   0     0           1     0       2           0    0\n",
      "TypeScript   0    0    0   0     0           0     0       0           0    1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.00      0.00      0.00         1\n",
      "         C++       0.00      0.00      0.00         3\n",
      "         CSS       0.00      0.00      0.00         1\n",
      "          Go       0.10      0.50      0.17         2\n",
      "        Java       1.00      0.75      0.86         4\n",
      "  JavaScript       0.67      0.67      0.67        15\n",
      "        None       0.38      0.38      0.38         8\n",
      "      Python       0.50      0.40      0.44         5\n",
      "  TypeScript       0.00      0.00      0.00         2\n",
      "         Vue       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.45        42\n",
      "   macro avg       0.26      0.27      0.25        42\n",
      "weighted avg       0.47      0.45      0.45        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.score_your_model(test.actual, test.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
